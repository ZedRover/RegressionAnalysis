{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn import datasets ## imports datasets from scikit-learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_boston() ## loads Boston dataset from datasets library \n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "target = pd.DataFrame(data.target, columns=[\"MEDV\"])\n",
    "# Concatenate y in the dataframe\n",
    "df_target = pd.concat([df,target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(df_target[['MEDV','CHAS','LSTAT','CRIM','RM','AGE']])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Nested Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_1 = smf.ols(formula='MEDV ~ CHAS + np.log(LSTAT)', data=df_target).fit()\n",
    "model_2 = smf.ols(formula='MEDV ~ CHAS + np.log(LSTAT) + RM + AGE', data=df_target).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anovaResults = anova_lm(model_1, model_2)\n",
    "print(anovaResults) \n",
    "# Notes:\n",
    "# 1. You can ignore the warnings. The warnings are because the values in the first line are empty (NaN). \n",
    "#    numpy package will issue warnings for NaN values\n",
    "# 2. ssr in the output are RSS or SSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create some dummy variables for categorical variables. This is another way of including categorical varaibles\n",
    "df_dummy = pd.get_dummies(df, columns = ['CHAS'],drop_first = True) # Change categorical to one-hot\n",
    "df_dummy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "#Importing tqdm for the progress bar\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "\n",
    "#Initialization variables\n",
    "y = target\n",
    "X = df_dummy.drop(columns=['ZN','INDUS','NOX','RAD']) # we don't include these variables in the model\n",
    "k = 9\n",
    "RSS_list, R_squared_list, adj_R_squared_list, AIC_list, BIC_list, feature_list = [],[],[],[],[],[]\n",
    "numb_features = []\n",
    "\n",
    "#Looping over k = 1 to k = 11 features in X\n",
    "for k in tnrange(1,len(X.columns) + 1, desc = 'Loop...'): # note that for python range(2) = 0,1\n",
    "\n",
    "    #Looping over all possible combinations: from 11 choose k\n",
    "    for combo in itertools.combinations(X.columns,k):\n",
    "        X_c = sm.add_constant(X[list(combo)])       # we need to add constant term using sm.OLS\n",
    "        model = sm.OLS(y, X_c).fit()                # run the regression model\n",
    "        \n",
    "        RSS_list.append(model.ssr)                  # model.ssr is the sum of squared residuals\n",
    "        R_squared_list.append(model.rsquared)\n",
    "        adj_R_squared_list.append(model.rsquared_adj)\n",
    "        AIC_list.append(model.aic)\n",
    "        BIC_list.append(model.bic)\n",
    "        feature_list.append(combo)\n",
    "        numb_features.append(len(combo))   \n",
    "\n",
    "# Store the results in DataFrame\n",
    "df_results = pd.DataFrame({'numb_features': numb_features,'RSS': RSS_list,'R_squared':R_squared_list,'features':feature_list,'adj_R_squared':adj_R_squared_list,'AIC':AIC_list,'BIC':BIC_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the minimum RSS for each numb_features\n",
    "df_minRSS = df_results[df_results.groupby('numb_features')['RSS'].transform(min) == df_results['RSS']] \n",
    "df_minRSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max R^2 for each numb_features. \n",
    "# We can verify that it is the same as min RSS\n",
    "df_maxRsqr = df_results[df_results.groupby('numb_features')['R_squared'].transform(max) == df_results['R_squared']] \n",
    "df_maxRsqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding columns to the dataframe with RSS and R squared values of the best subset\n",
    "# This is for plotting purpose only\n",
    "df_results['min_RSS'] = df_results.groupby('numb_features')['RSS'].transform(min)\n",
    "df_results['max_R_squared'] = df_results.groupby('numb_features')['R_squared'].transform(max)\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "ax.scatter(df_results.numb_features,df_results.RSS, alpha = .2, color = 'darkblue' )\n",
    "ax.set_xlabel('# Features')\n",
    "ax.set_ylabel('RSS')\n",
    "ax.set_title('RSS - Best subset selection')\n",
    "ax.plot(df_results.numb_features,df_results.min_RSS,color = 'r', label = 'Best subset')\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.scatter(df_results.numb_features,df_results.R_squared, alpha = .2, color = 'darkblue' )\n",
    "ax.plot(df_results.numb_features,df_results.max_R_squared,color = 'r', label = 'Best subset')\n",
    "ax.set_xlabel('# Features')\n",
    "ax.set_ylabel('R squared')\n",
    "ax.set_title('R_squared - Best subset selection')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "# Ignore the warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards = ['AIC','BIC','adj_R_squared']\n",
    "df_maxRsqr.index = df_maxRsqr.numb_features       # need to reset index to 1,2,3.. for this to plot the red X\n",
    "fig = plt.figure(figsize = (18,6))\n",
    "\n",
    "for i,v in enumerate(standards):\n",
    "    ax = fig.add_subplot(1, len(standards), i+1)\n",
    "    ax.plot(df_maxRsqr['numb_features'],df_maxRsqr[v], color = 'lightblue')\n",
    "    ax.scatter(df_maxRsqr['numb_features'],df_maxRsqr[v], color = 'darkblue')\n",
    "    if v == 'adj_R_squared':\n",
    "        ax.plot(df_maxRsqr[v].idxmax(),df_maxRsqr[v].max(), marker = 'x', markersize = 20, color='r')\n",
    "    else:\n",
    "        ax.plot(df_maxRsqr[v].idxmin(),df_maxRsqr[v].min(), marker = 'x', markersize = 20, color='r')\n",
    "    ax.set_xlabel('Number of predictors')\n",
    "    ax.set_ylabel(v)\n",
    "\n",
    "fig.suptitle('Subset selection using AIC, BIC, Adjusted R2', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward Stepwise Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialization variables\n",
    "y = target\n",
    "X = df_dummy.drop(columns=['ZN','INDUS','NOX','RAD'])     # we don't include these variables in the model\n",
    "k = 9\n",
    "\n",
    "remaining_features = list(X.columns.values)               # Initialize the remaining features as all features\n",
    "features = []\n",
    "RSS_list, R_squared_list, adj_R_squared_list, AIC_list, BIC_list = [],[],[],[],[] \n",
    "features_list = dict()                                    # Intialize feature list using dictionary. This is one way\n",
    "\n",
    "for i in range(1,k+1):\n",
    "    best_RSS = np.inf                                     # initialize the best_RSS in each round to be infinity\n",
    "    \n",
    "    for combo in itertools.combinations(remaining_features,1): # iterate through all remaining features\n",
    "        \n",
    "        X_c = sm.add_constant(X[list(combo) + features])  # we need to add constant term using sm.OLS\n",
    "        model = sm.OLS(y, X_c).fit()\n",
    "\n",
    "        if model.ssr < best_RSS:                          # compare the RSS value with the smallest value in this round\n",
    "            best_RSS = model.ssr                          # update the best value\n",
    "            best_R_squared = model.rsquared               # update best best_R_squared\n",
    "            best_feature = combo[0]                       # the best feature in this round\n",
    "            best_aic = model.aic\n",
    "            best_bic = model.bic\n",
    "            best_adj_R_squared = model.rsquared_adj\n",
    "\n",
    "    #Updating variables for next loop\n",
    "    features.append(best_feature)                         # add the best feature in the features set\n",
    "    remaining_features.remove(best_feature)               # remove it from candidate set\n",
    "    \n",
    "    #Saving values for plotting\n",
    "    RSS_list.append(best_RSS)\n",
    "    R_squared_list.append(best_R_squared)\n",
    "    AIC_list.append(best_aic)\n",
    "    BIC_list.append(best_bic)\n",
    "    adj_R_squared_list.append(best_adj_R_squared)\n",
    "    features_list[i] = features.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results in df_results, which is a joint of df_features and df_values\n",
    "df_features = pd.DataFrame({'features':features_list})\n",
    "df_values = pd.DataFrame({'RSS':RSS_list, 'R_squared': R_squared_list,'AIC':AIC_list,'BIC':BIC_list, 'adj_R_squared': adj_R_squared_list})\n",
    "df_values.index += 1  # shift the index by 1 to get aligned with df_features\n",
    "df_results = pd.concat([df_features,df_values], axis=1, join='inner')\n",
    "df_results['numb_features'] = df_results.index\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards = ['AIC','BIC','adj_R_squared']\n",
    "fig = plt.figure(figsize = (18,6))\n",
    "\n",
    "for i,v in enumerate(standards):\n",
    "    ax = fig.add_subplot(1, len(standards), i+1)\n",
    "    ax.plot(df_results['numb_features'],df_results[v], color = 'lightblue')\n",
    "    ax.scatter(df_results['numb_features'],df_results[v], color = 'darkblue')\n",
    "    if v == 'adj_R_squared':\n",
    "        ax.plot(df_results[v].idxmax(),df_results[v].max(), marker = 'x', markersize = 20, color='r')\n",
    "    else:\n",
    "        ax.plot(df_results[v].idxmin(),df_results[v].min(), marker = 'x', markersize = 20, color='r')\n",
    "    ax.set_xlabel('Number of predictors')\n",
    "    ax.set_ylabel(v)\n",
    "\n",
    "fig.suptitle('Subset selection using AIC, BIC, Adjusted R2', fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can define a function to ensulate the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_subset(y, X):\n",
    "    import itertools\n",
    "    from tqdm import tnrange, tqdm_notebook #Importing tqdm for the progress bar\n",
    "    RSS_list, R_squared_list,adj_R_squared_list, AIC_list, BIC_list, feature_list = [],[],[],[],[],[]\n",
    "    numb_features = []\n",
    "    k = len(X.columns)\n",
    "    #Looping over k = 1 to k = 11 features in X\n",
    "    for k in tnrange(1,len(X.columns) + 1, desc = 'Loop...'): # note that for python range(2) = 0,1\n",
    "\n",
    "        #Looping over all possible combinations: from 11 choose k\n",
    "        for combo in itertools.combinations(X.columns,k):\n",
    "            X_c = sm.add_constant(X[list(combo)])       # we need to add constant term using sm.OLS\n",
    "            model = sm.OLS(y, X_c).fit()                # run the regression model\n",
    "            RSS_list.append(model.ssr)                  # model.ssr is the sum of squared residuals\n",
    "            R_squared_list.append(model.rsquared)\n",
    "            adj_R_squared_list.append(model.rsquared_adj)\n",
    "            AIC_list.append(model.aic)\n",
    "            BIC_list.append(model.bic)\n",
    "            feature_list.append(combo)\n",
    "            numb_features.append(len(combo))   \n",
    "\n",
    "    # Store the results in DataFrame\n",
    "    df_results = pd.DataFrame({'numb_features': numb_features,'RSS': RSS_list,'R_squared':R_squared_list,\n",
    "                               'features':feature_list,'adj_R_squared':adj_R_squared_list,'AIC':AIC_list,'BIC':BIC_list})\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_stepwise(y, X, remaining_features):\n",
    "    features = []\n",
    "    RSS_list, R_squared_list, adj_R_squared_list, AIC_list, BIC_list = [],[],[],[],[] \n",
    "    features_list = dict()                                    # Intialize feature list using dictionary. This is one way\n",
    "    k = len(remaining_features)\n",
    "    for i in range(1,k+1):\n",
    "        best_RSS = np.inf                                     # initialize the best_RSS in each round to be infinity\n",
    "\n",
    "        for combo in itertools.combinations(remaining_features,1): # iterate through all remaining features\n",
    "\n",
    "            X_c = sm.add_constant(X[list(combo) + features])  # we need to add constant term using sm.OLS\n",
    "            model = sm.OLS(y, X_c).fit()\n",
    "\n",
    "            if model.ssr < best_RSS:                          # compare the RSS value with the smallest value in this round\n",
    "                best_RSS = model.ssr                          # update the best value\n",
    "                best_R_squared = model.rsquared               # update best best_R_squared\n",
    "                best_feature = combo[0]                       # the best feature in this round\n",
    "                best_aic = model.aic\n",
    "                best_bic = model.bic\n",
    "                best_adj_R_squared = model.rsquared_adj\n",
    "\n",
    "        #Updating variables for next loop\n",
    "        features.append(best_feature)                         # add the best feature in the features set\n",
    "        remaining_features.remove(best_feature)               # remove it from candidate set\n",
    "\n",
    "        #Saving values for plotting\n",
    "        RSS_list.append(best_RSS)\n",
    "        R_squared_list.append(best_R_squared)\n",
    "        AIC_list.append(best_aic)\n",
    "        BIC_list.append(best_bic)\n",
    "        adj_R_squared_list.append(best_adj_R_squared)\n",
    "        features_list[i] = features.copy()\n",
    "\n",
    "    # store results in df_results, which is a joint of df_features and df_values\n",
    "    df_features = pd.DataFrame({'features':features_list})\n",
    "    df_values = pd.DataFrame({'RSS':RSS_list, 'R_squared': R_squared_list,'AIC':AIC_list,'BIC':BIC_list, 'adj_R_squared': adj_R_squared_list})\n",
    "    df_values.index += 1  # shift the index by 1 to get aligned with df_features\n",
    "    df_results = pd.concat([df_features,df_values], axis=1, join='inner')\n",
    "    df_results['numb_features'] = df_results.index\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_selection(df_results, standards):\n",
    "    fig = plt.figure(figsize = (18,6))\n",
    "\n",
    "    for i,v in enumerate(standards):\n",
    "        ax = fig.add_subplot(1, len(standards), i+1)\n",
    "        ax.plot(df_results['numb_features'],df_results[v], color = 'lightblue')\n",
    "        ax.scatter(df_results['numb_features'],df_results[v], color = 'darkblue')\n",
    "        if v == 'adj_R_squared':\n",
    "            ax.plot(df_results[v].idxmax(),df_results[v].max(), marker = 'x', markersize = 20, color='r')\n",
    "        else:\n",
    "            ax.plot(df_results[v].idxmin(),df_results[v].min(), marker = 'x', markersize = 20, color='r')\n",
    "        ax.set_xlabel('Number of predictors')\n",
    "        ax.set_ylabel(v)\n",
    "\n",
    "    fig.suptitle('Subset selection using ' + \", \".join(standards), fontsize = 16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best subset vs. forward stepwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialization variables\n",
    "y = target\n",
    "X = df_dummy.drop(columns=['ZN','INDUS','NOX','RAD','AGE','PTRATIO','B']) # we don't include these variables in the model\n",
    "df_results_BS = best_subset(y, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialization variables\n",
    "y = target\n",
    "X = df_dummy.drop(columns=['ZN','INDUS','NOX','RAD','AGE','PTRATIO','B'])     # we don't include these variables in the model\n",
    "remaining_features = list(X.columns.values)               # Initialize the remaining features as all features\n",
    "df_results_FS = forward_stepwise(y, X, remaining_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maxRsqr = df_results_BS[df_results_BS.groupby('numb_features')['R_squared'].transform(max) == df_results_BS['R_squared']] # Get max R^2 for each number of predictors\n",
    "df_maxRsqr.index = df_maxRsqr.numb_features\n",
    "standards = ['AIC','BIC','adj_R_squared']\n",
    "plot_selection(df_maxRsqr, standards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standards = ['AIC','BIC','adj_R_squared']\n",
    "plot_selection(df_results_FS, standards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
